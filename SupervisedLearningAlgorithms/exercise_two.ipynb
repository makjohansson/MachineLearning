{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2:One versus all MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from utils import A3, mnist_reader\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function mnist_reader saves the cvs file as a pickle file and returns the dataset as a numpy array\n",
    "X_train has the shape (60000, 784), that is that there is 60000 images with 784 columns and every column has a value 0 -255.<br>\n",
    "0 is the colour white and 255 is the color black. Numbers inbetween are different shades of gray. To make the model easier to train\n",
    "the values < 0 will is converted to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "data_train =  mnist_reader.load_mnist_dataset('mnist_train.csv') # load the mnist train set as a numpy array\n",
    "data_test = mnist_reader.load_mnist_dataset('mnist_test.csv') # load the test set as a numpy array\n",
    "X_train = data_train[:, 1:]\n",
    "y_train = data_train[:, 0]\n",
    "X_test = data_test[:, 1:]\n",
    "y_test = data_test[:, 0]\n",
    "X_train[X_train>0] = 1\n",
    "X_test[X_test>0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the parameter tuning I set aside a validation set. \n",
    "This set is used in the parameter search and not included when training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter tuning...\n",
      "   param_C param_gamma  mean_test_score\n",
      "0     0.01      0.0001         0.135000\n",
      "1     0.01       0.001         0.135000\n",
      "2     0.01        0.01         0.135000\n",
      "3     0.01         0.1         0.125000\n",
      "4      0.1      0.0001         0.135000\n",
      "5      0.1       0.001         0.135000\n",
      "6      0.1        0.01         0.371667\n",
      "7      0.1         0.1         0.125000\n",
      "8        1      0.0001         0.156667\n",
      "9        1       0.001         0.795000\n",
      "10       1        0.01         0.865000\n",
      "11       1         0.1         0.270000\n",
      "12      10      0.0001         0.796667\n",
      "13      10       0.001         0.851667\n",
      "14      10        0.01         0.885000\n",
      "15      10         0.1         0.291667\n",
      "16     100      0.0001         0.848333\n",
      "17     100       0.001         0.861667\n",
      "18     100        0.01         0.885000\n",
      "19     100         0.1         0.291667\n",
      "Best params: {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Best score: 0.885\n",
      "Best estimator: SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.01, random_state=42)\n",
    "\n",
    "params = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'gamma': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'kernel':['rbf']} \n",
    "\n",
    "svc = SVC()\n",
    "print('Hyperparameter tuning...')\n",
    "grid_search = GridSearchCV(svc, params, cv=5)\n",
    "grid_search.fit(X_validation, y_validation)\n",
    "df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "print(df[['param_C', 'param_gamma', 'mean_test_score']])\n",
    "print('Best params:',grid_search.best_params_)\n",
    "print('Best score:', grid_search.best_score_)\n",
    "print('Best estimator:', grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-vs-one classifiers, sklearn\n",
    "<ul>\n",
    "   <li>Using the best hyperparameters to train the model with the trainingset</li>\n",
    "   <li>Saving the trained classifier</li>\n",
    "</ul>\n",
    "First time I save the model using the out commented code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded\n"
     ]
    }
   ],
   "source": [
    "#print('Training model...')\n",
    "#clf = SVC(kernel='rbf', C=10, gamma=0.01)\n",
    "# clf.fit(X_train, y_train)\n",
    "# x = clf.score(X_test, y_test)\n",
    "# print('Result', x)\n",
    "# # Joblib is more efficient on big data\n",
    "# print('Saveing model...')\n",
    "# dump(clf, 'mnist_clf.joblib')\n",
    "clf = load('utils/classifiers/mnist_clf.joblib')\n",
    "print('Model successfully loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "   <li>Create a confusion matrix</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 98.13%\n",
      "[[ 972    0    0    0    0    1    2    1    3    1]\n",
      " [   1 1123    2    1    1    1    2    0    4    0]\n",
      " [   4    0 1018    1    1    0    0    4    4    0]\n",
      " [   0    0    2  996    0    2    0    3    5    2]\n",
      " [   2    0    2    0  961    0    3    1    1   12]\n",
      " [   2    0    0   10    0  865    5    1    7    2]\n",
      " [   4    2    0    0    1    4  944    0    3    0]\n",
      " [   1    2    6    1    1    0    0 1009    1    7]\n",
      " [   4    1    3    6    3    1    2    3  949    2]\n",
      " [   1    6    1    7    8    4    0    4    2  976]]\n"
     ]
    }
   ],
   "source": [
    "prediciton = clf.predict(X_test)\n",
    "print('Model accuracy:', str(100 * np.mean(prediciton == y_test)) + '%')\n",
    "cm = confusion_matrix(y_test, prediciton)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-vs-all classifiers\n",
    "<ul>\n",
    "   <li>Traning and testing the classifiers</li>\n",
    "   <li>Create a confusion matrix</li>\n",
    "</ul>\n",
    "First time I trained and saved the classifiers using the out commented code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running one vs all...\n",
      "Model accuracy: 98.22%\n",
      "Building confusion matrix...\n",
      "[[ 972    1    0    1    1    0    2    1    1    1]\n",
      " [   1 1123    3    1    0    2    2    0    3    0]\n",
      " [   4    0 1014    3    1    0    0    5    5    0]\n",
      " [   0    0    1  990    1    3    0    3    9    3]\n",
      " [   0    0    3    0  962    0    2    1    3   11]\n",
      " [   2    0    0    9    0  871    4    0    5    1]\n",
      " [   3    2    0    0    1    4  943    0    5    0]\n",
      " [   1    0    5    2    0    0    0 1013    2    5]\n",
      " [   2    1    3    3    2    1    1    3  956    2]\n",
      " [   4    5    1    8    7    2    0    2    2  978]]\n"
     ]
    }
   ],
   "source": [
    "# X = X_train\n",
    "# y = y_train\n",
    "X = X_test\n",
    "y = y_test\n",
    "print('Running one vs all...')\n",
    "yy = A3.one_vs_all(X,y, 10)\n",
    "print('Model accuracy:', str(100 * np.mean(yy == y)) + '%')\n",
    "print('Building confusion matrix...')\n",
    "cm = confusion_matrix(y, yy)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-vs-one vs One-vs-all\n",
    "I get a slightly better result using the one-vs-all to make predicitons, the resluts differ with 0.09% so the time it took to train the one-vs-all classifiers was not worth it. By studing the confusin matrix it is shown that the two methods results are very much alike. It is the same features that they have high respectively low error rate on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
